# GitHub Actions é›†æˆä¼˜åŒ–æ–¹æ¡ˆ

## ğŸ“‹ æ–¹æ¡ˆæ¦‚è¿°

åŸºäº Easy ERP é¡¹ç›®çš„æ•°æ®åº“åŒæ­¥ä¼˜åŒ–éœ€æ±‚ï¼Œè®¾è®¡å®Œæ•´çš„ GitHub Actions CI/CD é›†æˆæ–¹æ¡ˆï¼Œå®ç°æ•°æ®åº“è¿ç§»ã€å¤‡ä»½æ¢å¤ã€ç›‘æ§å‘Šè­¦çš„è‡ªåŠ¨åŒ–æµç¨‹ï¼Œç¡®ä¿ä»£ç å˜æ›´çš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚

## ğŸ¯ é›†æˆç›®æ ‡

### æ ¸å¿ƒç›®æ ‡
- **è‡ªåŠ¨åŒ–æ•°æ®åº“è¿ç§»**: ä»£ç åˆå¹¶æ—¶è‡ªåŠ¨æ‰§è¡Œæ•°æ®åº“è¿ç§»
- **å®‰å…¨æ€§ä¿éšœ**: è¿ç§»å‰è‡ªåŠ¨å¤‡ä»½ï¼Œå¤±è´¥æ—¶è‡ªåŠ¨å›æ»š
- **è´¨é‡é—¨æ§**: å¤šç¯å¢ƒéªŒè¯ï¼Œç¡®ä¿è¿ç§»å®‰å…¨æ€§
- **ç›‘æ§é›†æˆ**: å®æ—¶ç›‘æ§è¿ç§»è¿‡ç¨‹ï¼Œå¼‚å¸¸æ—¶ç«‹å³å‘Šè­¦
- **å¯è¿½æº¯æ€§**: å®Œæ•´çš„æ“ä½œæ—¥å¿—å’Œå®¡è®¡è®°å½•

### æ€§èƒ½æŒ‡æ ‡
- **éƒ¨ç½²æ—¶é—´**: å®Œæ•´æµç¨‹ â‰¤ 10åˆ†é’Ÿ
- **æˆåŠŸç‡**: è‡ªåŠ¨åŒ–éƒ¨ç½²æˆåŠŸç‡ â‰¥ 99%
- **å›æ»šæ—¶é—´**: å¼‚å¸¸å›æ»šæ—¶é—´ â‰¤ 2åˆ†é’Ÿ
- **ç›‘æ§è¦†ç›–**: å…³é”®æ­¥éª¤ç›‘æ§è¦†ç›–ç‡ 100%

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ•´ä½“æµç¨‹æ¶æ„
```mermaid
graph TB
    subgraph "ä»£ç å˜æ›´è§¦å‘"
        A1["Pull Request"]
        A2["Push to Main"]
        A3["Release Tag"]
    end
    
    subgraph "é¢„æ£€æŸ¥é˜¶æ®µ"
        B1["ä»£ç è´¨é‡æ£€æŸ¥"]
        B2["æ•°æ®åº“è¿ç§»éªŒè¯"]
        B3["å®‰å…¨æ‰«æ"]
        B4["ä¾èµ–æ£€æŸ¥"]
    end
    
    subgraph "æµ‹è¯•ç¯å¢ƒéƒ¨ç½²"
        C1["åˆ›å»ºæµ‹è¯•æ•°æ®åº“"]
        C2["æ‰§è¡Œè¿ç§»è„šæœ¬"]
        C3["è¿è¡Œé›†æˆæµ‹è¯•"]
        C4["æ€§èƒ½åŸºå‡†æµ‹è¯•"]
    end
    
    subgraph "ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²"
        D1["ç”Ÿäº§æ•°æ®åº“å¤‡ä»½"]
        D2["è“ç»¿éƒ¨ç½²å‡†å¤‡"]
        D3["æ‰§è¡Œæ•°æ®åº“è¿ç§»"]
        D4["åº”ç”¨éƒ¨ç½²"]
        D5["å¥åº·æ£€æŸ¥"]
        D6["æµé‡åˆ‡æ¢"]
    end
    
    subgraph "ç›‘æ§å‘Šè­¦"
        E1["è¿ç§»è¿‡ç¨‹ç›‘æ§"]
        E2["æ€§èƒ½æŒ‡æ ‡ç›‘æ§"]
        E3["å¼‚å¸¸å‘Šè­¦"]
        E4["è‡ªåŠ¨å›æ»š"]
    end
    
    subgraph "åç½®å¤„ç†"
        F1["æ¸…ç†ä¸´æ—¶èµ„æº"]
        F2["æ›´æ–°éƒ¨ç½²è®°å½•"]
        F3["å‘é€é€šçŸ¥"]
        F4["ç”ŸæˆæŠ¥å‘Š"]
    end
    
    A1 --> B1
    A2 --> B1
    A3 --> B1
    
    B1 --> B2
    B2 --> B3
    B3 --> B4
    B4 --> C1
    
    C1 --> C2
    C2 --> C3
    C3 --> C4
    C4 --> D1
    
    D1 --> D2
    D2 --> D3
    D3 --> D4
    D4 --> D5
    D5 --> D6
    
    D3 --> E1
    D4 --> E2
    E1 --> E3
    E2 --> E3
    E3 --> E4
    
    D6 --> F1
    E4 --> F1
    F1 --> F2
    F2 --> F3
    F3 --> F4
```

### ç¯å¢ƒåˆ†å±‚è®¾è®¡

```mermaid
graph LR
    subgraph "å¼€å‘ç¯å¢ƒ"
        A1["Feature Branch"]
        A2["æœ¬åœ°æ•°æ®åº“"]
        A3["å¼€å‘è€…æµ‹è¯•"]
    end
    
    subgraph "æµ‹è¯•ç¯å¢ƒ"
        B1["PR Validation"]
        B2["æµ‹è¯•æ•°æ®åº“"]
        B3["è‡ªåŠ¨åŒ–æµ‹è¯•"]
        B4["é›†æˆæµ‹è¯•"]
    end
    
    subgraph "é¢„å‘å¸ƒç¯å¢ƒ"
        C1["Staging Deploy"]
        C2["ç”Ÿäº§æ•°æ®å‰¯æœ¬"]
        C3["æ€§èƒ½æµ‹è¯•"]
        C4["ç”¨æˆ·éªŒæ”¶æµ‹è¯•"]
    end
    
    subgraph "ç”Ÿäº§ç¯å¢ƒ"
        D1["Production Deploy"]
        D2["ç”Ÿäº§æ•°æ®åº“"]
        D3["è“ç»¿éƒ¨ç½²"]
        D4["ç›‘æ§å‘Šè­¦"]
    end
    
    A1 --> B1
    B1 --> C1
    C1 --> D1
```

## ğŸ”§ Workflow å®ç°

### 1. ä¸»å·¥ä½œæµé…ç½®

```yaml
# .github/workflows/database-sync-ci.yml
name: Database Sync CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  release:
    types: [ published ]

env:
  NODE_VERSION: '18'
  MYSQL_VERSION: '8.0'
  MONITORING_ENABLED: true

jobs:
  # é¢„æ£€æŸ¥é˜¶æ®µ
  pre-checks:
    name: Pre-deployment Checks
    runs-on: ubuntu-latest
    outputs:
      has-migrations: ${{ steps.check-migrations.outputs.has-migrations }}
      migration-hash: ${{ steps.check-migrations.outputs.migration-hash }}
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'
      
      - name: Install Dependencies
        run: pnpm install --frozen-lockfile
      
      - name: Code Quality Check
        run: |
          pnpm run lint
          pnpm run type-check
          pnpm run test:unit
      
      - name: Security Scan
        run: |
          pnpm audit --audit-level moderate
          npx snyk test --severity-threshold=high
      
      - name: Check Database Migrations
        id: check-migrations
        run: |
          # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„è¿ç§»æ–‡ä»¶
          MIGRATION_FILES=$(git diff --name-only ${{ github.event.before }}..${{ github.sha }} -- prisma/migrations/ || echo "")
          if [ -n "$MIGRATION_FILES" ]; then
            echo "has-migrations=true" >> $GITHUB_OUTPUT
            echo "Found migration files: $MIGRATION_FILES"
            
            # ç”Ÿæˆè¿ç§»æ–‡ä»¶å“ˆå¸Œ
            MIGRATION_HASH=$(find prisma/migrations -name "*.sql" -exec cat {} \; | sha256sum | cut -d' ' -f1)
            echo "migration-hash=$MIGRATION_HASH" >> $GITHUB_OUTPUT
          else
            echo "has-migrations=false" >> $GITHUB_OUTPUT
          fi
      
      - name: Validate Migration Scripts
        if: steps.check-migrations.outputs.has-migrations == 'true'
        run: |
          # éªŒè¯è¿ç§»è„šæœ¬è¯­æ³•
          pnpm prisma validate
          pnpm prisma format --check
          
          # æ£€æŸ¥è¿ç§»è„šæœ¬æ˜¯å¦åŒ…å«å±é™©æ“ä½œ
          ./scripts/validate-migrations.sh
      
      - name: Upload Migration Artifacts
        if: steps.check-migrations.outputs.has-migrations == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: migration-files-${{ steps.check-migrations.outputs.migration-hash }}
          path: |
            prisma/migrations/
            prisma/schema.prisma
          retention-days: 30

  # æµ‹è¯•ç¯å¢ƒéƒ¨ç½²
  test-deployment:
    name: Test Environment Deployment
    runs-on: ubuntu-latest
    needs: pre-checks
    if: needs.pre-checks.outputs.has-migrations == 'true'
    
    services:
      mysql:
        image: mysql:8.0
        env:
          MYSQL_ROOT_PASSWORD: test_password
          MYSQL_DATABASE: easy_erp_test
        ports:
          - 3306:3306
        options: >
          --health-cmd="mysqladmin ping -h localhost"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5
      
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >
          --health-cmd="redis-cli ping"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'
      
      - name: Install Dependencies
        run: pnpm install --frozen-lockfile
      
      - name: Setup Test Database
        env:
          DATABASE_URL: mysql://root:test_password@localhost:3306/easy_erp_test
        run: |
          # ç­‰å¾…æ•°æ®åº“å°±ç»ª
          ./scripts/wait-for-db.sh
          
          # åˆ›å»ºæµ‹è¯•æ•°æ®
          pnpm prisma db push
          pnpm prisma db seed
      
      - name: Run Database Migration
        env:
          DATABASE_URL: mysql://root:test_password@localhost:3306/easy_erp_test
        run: |
          # è®°å½•è¿ç§»å¼€å§‹æ—¶é—´
          echo "MIGRATION_START=$(date -u +%Y-%m-%dT%H:%M:%SZ)" >> $GITHUB_ENV
          
          # æ‰§è¡Œè¿ç§»
          pnpm prisma migrate deploy
          
          # éªŒè¯è¿ç§»ç»“æœ
          pnpm prisma db pull
          git diff --exit-code prisma/schema.prisma || {
            echo "Schema mismatch detected after migration"
            exit 1
          }
      
      - name: Run Integration Tests
        env:
          DATABASE_URL: mysql://root:test_password@localhost:3306/easy_erp_test
          REDIS_URL: redis://localhost:6379
        run: |
          pnpm run test:integration
          pnpm run test:e2e
      
      - name: Performance Benchmark
        env:
          DATABASE_URL: mysql://root:test_password@localhost:3306/easy_erp_test
        run: |
          # è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
          pnpm run test:performance
          
          # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
          ./scripts/generate-performance-report.sh
      
      - name: Upload Test Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ github.sha }}
          path: |
            test-results/
            coverage/
            performance-report.json

  # ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
  production-deployment:
    name: Production Deployment
    runs-on: ubuntu-latest
    needs: [pre-checks, test-deployment]
    if: |
      github.ref == 'refs/heads/main' && 
      needs.pre-checks.outputs.has-migrations == 'true' &&
      needs.test-deployment.result == 'success'
    environment:
      name: production
      url: https://erp.company.com
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'
      
      - name: Install Dependencies
        run: pnpm install --frozen-lockfile
      
      - name: Download Migration Artifacts
        uses: actions/download-artifact@v4
        with:
          name: migration-files-${{ needs.pre-checks.outputs.migration-hash }}
      
      - name: Setup Production Database Connection
        run: |
          # é…ç½®ç”Ÿäº§æ•°æ®åº“è¿æ¥
          echo "DATABASE_URL=${{ secrets.PRODUCTION_DATABASE_URL }}" >> $GITHUB_ENV
          echo "BACKUP_STORAGE_URL=${{ secrets.BACKUP_STORAGE_URL }}" >> $GITHUB_ENV
          
          # éªŒè¯æ•°æ®åº“è¿æ¥
          ./scripts/verify-db-connection.sh
      
      - name: Create Database Backup
        id: backup
        run: |
          # åˆ›å»ºè¿ç§»å‰å¤‡ä»½
          BACKUP_ID=$(date +%Y%m%d_%H%M%S)_migration_${{ github.sha }}
          echo "backup-id=$BACKUP_ID" >> $GITHUB_OUTPUT
          
          # æ‰§è¡Œå¤‡ä»½
          ./scripts/create-backup.sh $BACKUP_ID
          
          # éªŒè¯å¤‡ä»½å®Œæ•´æ€§
          ./scripts/verify-backup.sh $BACKUP_ID
          
          echo "Backup created: $BACKUP_ID"
      
      - name: Enable Maintenance Mode
        run: |
          # å¯ç”¨ç»´æŠ¤æ¨¡å¼
          ./scripts/enable-maintenance-mode.sh
          
          # ç­‰å¾…æ´»è·ƒè¿æ¥ç»“æŸ
          ./scripts/wait-for-connections-drain.sh
      
      - name: Execute Database Migration
        id: migration
        run: |
          # è®°å½•è¿ç§»å¼€å§‹æ—¶é—´
          echo "MIGRATION_START=$(date -u +%Y-%m-%dT%H:%M:%SZ)" >> $GITHUB_ENV
          
          # å¯åŠ¨ç›‘æ§
          ./scripts/start-migration-monitoring.sh &
          MONITOR_PID=$!
          echo "monitor-pid=$MONITOR_PID" >> $GITHUB_OUTPUT
          
          # æ‰§è¡Œè¿ç§»
          timeout 600 pnpm prisma migrate deploy || {
            echo "Migration timed out or failed"
            kill $MONITOR_PID 2>/dev/null || true
            exit 1
          }
          
          # åœæ­¢ç›‘æ§
          kill $MONITOR_PID 2>/dev/null || true
          
          # éªŒè¯è¿ç§»ç»“æœ
          ./scripts/verify-migration.sh
      
      - name: Deploy Application
        run: |
          # æ„å»ºåº”ç”¨
          pnpm run build
          
          # éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
          ./scripts/deploy-application.sh
      
      - name: Health Check
        run: |
          # ç­‰å¾…åº”ç”¨å¯åŠ¨
          sleep 30
          
          # æ‰§è¡Œå¥åº·æ£€æŸ¥
          ./scripts/health-check.sh
          
          # éªŒè¯å…³é”®åŠŸèƒ½
          ./scripts/smoke-test.sh
      
      - name: Disable Maintenance Mode
        run: |
          # ç¦ç”¨ç»´æŠ¤æ¨¡å¼
          ./scripts/disable-maintenance-mode.sh
          
          # é€æ­¥æ¢å¤æµé‡
          ./scripts/gradual-traffic-restore.sh
      
      - name: Post-deployment Monitoring
        run: |
          # å¯åŠ¨éƒ¨ç½²åç›‘æ§
          ./scripts/start-post-deployment-monitoring.sh
          
          # ç­‰å¾…ç›‘æ§ç¨³å®š
          sleep 300
          
          # æ£€æŸ¥å…³é”®æŒ‡æ ‡
          ./scripts/check-deployment-metrics.sh
      
      - name: Cleanup on Failure
        if: failure()
        run: |
          echo "Deployment failed, initiating rollback..."
          
          # å›æ»šæ•°æ®åº“
          ./scripts/rollback-database.sh ${{ steps.backup.outputs.backup-id }}
          
          # å›æ»šåº”ç”¨
          ./scripts/rollback-application.sh
          
          # ç¦ç”¨ç»´æŠ¤æ¨¡å¼
          ./scripts/disable-maintenance-mode.sh
          
          # å‘é€å¤±è´¥é€šçŸ¥
          ./scripts/send-failure-notification.sh
      
      - name: Send Success Notification
        if: success()
        run: |
          ./scripts/send-success-notification.sh
      
      - name: Update Deployment Record
        if: always()
        run: |
          ./scripts/update-deployment-record.sh

  # ç›‘æ§å’Œå‘Šè­¦
  monitoring:
    name: Post-deployment Monitoring
    runs-on: ubuntu-latest
    needs: production-deployment
    if: always() && needs.production-deployment.result != 'skipped'
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
      
      - name: Setup Monitoring
        run: |
          # é…ç½®ç›‘æ§å‘Šè­¦
          ./scripts/setup-deployment-monitoring.sh
          
          # åˆ›å»ºä¸´æ—¶å‘Šè­¦è§„åˆ™
          ./scripts/create-deployment-alerts.sh
      
      - name: Monitor Deployment
        run: |
          # ç›‘æ§éƒ¨ç½²å30åˆ†é’Ÿ
          timeout 1800 ./scripts/monitor-deployment.sh || {
            echo "Monitoring completed or timed out"
          }
      
      - name: Generate Deployment Report
        run: |
          ./scripts/generate-deployment-report.sh
      
      - name: Cleanup Monitoring
        if: always()
        run: |
          # æ¸…ç†ä¸´æ—¶å‘Šè­¦è§„åˆ™
          ./scripts/cleanup-deployment-alerts.sh
```

### 2. è¿ç§»éªŒè¯å·¥ä½œæµ

```yaml
# .github/workflows/migration-validation.yml
name: Migration Validation

on:
  pull_request:
    paths:
      - 'prisma/migrations/**'
      - 'prisma/schema.prisma'

jobs:
  validate-migrations:
    name: Validate Database Migrations
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        mysql-version: ['8.0', '8.1']
    
    services:
      mysql:
        image: mysql:${{ matrix.mysql-version }}
        env:
          MYSQL_ROOT_PASSWORD: test_password
          MYSQL_DATABASE: migration_test
        ports:
          - 3306:3306
        options: >
          --health-cmd="mysqladmin ping -h localhost"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=10
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'pnpm'
      
      - name: Install Dependencies
        run: pnpm install --frozen-lockfile
      
      - name: Analyze Migration Changes
        run: |
          # åˆ†æè¿ç§»å˜æ›´
          ./scripts/analyze-migration-changes.sh
          
          # æ£€æŸ¥ç ´åæ€§å˜æ›´
          ./scripts/check-breaking-changes.sh
          
          # ä¼°ç®—è¿ç§»æ—¶é—´
          ./scripts/estimate-migration-time.sh
      
      - name: Test Migration on Empty Database
        env:
          DATABASE_URL: mysql://root:test_password@localhost:3306/migration_test
        run: |
          # åœ¨ç©ºæ•°æ®åº“ä¸Šæµ‹è¯•è¿ç§»
          pnpm prisma migrate deploy
          
          # éªŒè¯ schema ä¸€è‡´æ€§
          pnpm prisma db pull
          git diff --exit-code prisma/schema.prisma
      
      - name: Test Migration with Sample Data
        env:
          DATABASE_URL: mysql://root:test_password@localhost:3306/migration_test
        run: |
          # é‡ç½®æ•°æ®åº“
          pnpm prisma migrate reset --force
          
          # åˆ›å»ºæ—§ç‰ˆæœ¬ schema
          git checkout HEAD~1 -- prisma/
          pnpm prisma migrate deploy
          
          # æ’å…¥æµ‹è¯•æ•°æ®
          ./scripts/insert-sample-data.sh
          
          # åˆ‡æ¢åˆ°æ–°ç‰ˆæœ¬å¹¶è¿ç§»
          git checkout HEAD -- prisma/
          pnpm prisma migrate deploy
          
          # éªŒè¯æ•°æ®å®Œæ•´æ€§
          ./scripts/verify-data-integrity.sh
      
      - name: Performance Impact Test
        env:
          DATABASE_URL: mysql://root:test_password@localhost:3306/migration_test
        run: |
          # åˆ›å»ºå¤§é‡æµ‹è¯•æ•°æ®
          ./scripts/create-large-dataset.sh
          
          # æµ‹è¯•è¿ç§»æ€§èƒ½
          time pnpm prisma migrate deploy
          
          # æµ‹è¯•æŸ¥è¯¢æ€§èƒ½å½±å“
          ./scripts/test-query-performance.sh
      
      - name: Generate Migration Report
        run: |
          ./scripts/generate-migration-report.sh > migration-report.md
      
      - name: Comment PR with Report
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('migration-report.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });
```

### 3. å›æ»šå·¥ä½œæµ

```yaml
# .github/workflows/rollback.yml
name: Emergency Rollback

on:
  workflow_dispatch:
    inputs:
      backup_id:
        description: 'Backup ID to rollback to'
        required: true
        type: string
      reason:
        description: 'Rollback reason'
        required: true
        type: string
      confirm:
        description: 'Type "CONFIRM" to proceed with rollback'
        required: true
        type: string

jobs:
  rollback:
    name: Emergency Database Rollback
    runs-on: ubuntu-latest
    environment:
      name: production
    
    steps:
      - name: Validate Confirmation
        run: |
          if [ "${{ github.event.inputs.confirm }}" != "CONFIRM" ]; then
            echo "Rollback not confirmed. Exiting."
            exit 1
          fi
      
      - name: Checkout Code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'pnpm'
      
      - name: Install Dependencies
        run: pnpm install --frozen-lockfile
      
      - name: Verify Backup Exists
        run: |
          ./scripts/verify-backup-exists.sh ${{ github.event.inputs.backup_id }}
      
      - name: Enable Maintenance Mode
        run: |
          ./scripts/enable-maintenance-mode.sh
      
      - name: Create Pre-rollback Backup
        run: |
          CURRENT_BACKUP_ID=$(date +%Y%m%d_%H%M%S)_pre_rollback
          ./scripts/create-backup.sh $CURRENT_BACKUP_ID
          echo "Pre-rollback backup created: $CURRENT_BACKUP_ID"
      
      - name: Execute Rollback
        run: |
          ./scripts/rollback-database.sh ${{ github.event.inputs.backup_id }}
      
      - name: Verify Rollback
        run: |
          ./scripts/verify-rollback.sh
      
      - name: Disable Maintenance Mode
        run: |
          ./scripts/disable-maintenance-mode.sh
      
      - name: Send Rollback Notification
        run: |
          ./scripts/send-rollback-notification.sh \
            "${{ github.event.inputs.backup_id }}" \
            "${{ github.event.inputs.reason }}"
```

## ğŸ“œ æ”¯æŒè„šæœ¬å®ç°

### 1. è¿ç§»éªŒè¯è„šæœ¬

```bash
#!/bin/bash
# scripts/validate-migrations.sh

set -e

echo "=== éªŒè¯æ•°æ®åº“è¿ç§»è„šæœ¬ ==="

# æ£€æŸ¥å±é™©æ“ä½œ
check_dangerous_operations() {
    echo "æ£€æŸ¥å±é™©æ“ä½œ..."
    
    DANGEROUS_PATTERNS=(
        "DROP TABLE"
        "DROP DATABASE"
        "TRUNCATE"
        "DELETE FROM.*WHERE.*1=1"
        "UPDATE.*SET.*WHERE.*1=1"
    )
    
    for pattern in "${DANGEROUS_PATTERNS[@]}"; do
        if grep -r -i "$pattern" prisma/migrations/; then
            echo "âŒ å‘ç°å±é™©æ“ä½œ: $pattern"
            echo "è¯·ç¡®è®¤æ­¤æ“ä½œæ˜¯å¦å¿…è¦ï¼Œå¹¶æ·»åŠ é€‚å½“çš„å®‰å…¨æ£€æŸ¥"
            exit 1
        fi
    done
    
    echo "âœ… æœªå‘ç°å±é™©æ“ä½œ"
}

# æ£€æŸ¥è¿ç§»æ–‡ä»¶å‘½å
check_migration_naming() {
    echo "æ£€æŸ¥è¿ç§»æ–‡ä»¶å‘½å..."
    
    find prisma/migrations -name "*.sql" | while read -r file; do
        filename=$(basename "$file")
        if [[ ! $filename =~ ^[0-9]{14}_.*\.sql$ ]]; then
            echo "âŒ è¿ç§»æ–‡ä»¶å‘½åä¸è§„èŒƒ: $file"
            echo "åº”è¯¥éµå¾ªæ ¼å¼: YYYYMMDDHHMMSS_description.sql"
            exit 1
        fi
    done
    
    echo "âœ… è¿ç§»æ–‡ä»¶å‘½åè§„èŒƒ"
}

# æ£€æŸ¥è¿ç§»æ–‡ä»¶å¤§å°
check_migration_size() {
    echo "æ£€æŸ¥è¿ç§»æ–‡ä»¶å¤§å°..."
    
    MAX_SIZE=1048576  # 1MB
    
    find prisma/migrations -name "*.sql" | while read -r file; do
        size=$(stat -f%z "$file" 2>/dev/null || stat -c%s "$file")
        if [ "$size" -gt "$MAX_SIZE" ]; then
            echo "âš ï¸  è¿ç§»æ–‡ä»¶è¿‡å¤§: $file (${size} bytes)"
            echo "å»ºè®®å°†å¤§å‹è¿ç§»æ‹†åˆ†ä¸ºå¤šä¸ªå°è¿ç§»"
        fi
    done
    
    echo "âœ… è¿ç§»æ–‡ä»¶å¤§å°æ£€æŸ¥å®Œæˆ"
}

# æ£€æŸ¥ç´¢å¼•åˆ›å»º
check_index_creation() {
    echo "æ£€æŸ¥ç´¢å¼•åˆ›å»º..."
    
    if grep -r -i "CREATE.*INDEX" prisma/migrations/; then
        echo "âš ï¸  å‘ç°ç´¢å¼•åˆ›å»ºæ“ä½œ"
        echo "è¯·ç¡®è®¤:"
        echo "1. ç´¢å¼•åˆ›å»ºæ˜¯å¦ä½¿ç”¨ ALGORITHM=INPLACE"
        echo "2. æ˜¯å¦åœ¨ä½å³°æœŸæ‰§è¡Œ"
        echo "3. æ˜¯å¦è¯„ä¼°äº†å¯¹æ€§èƒ½çš„å½±å“"
    fi
    
    echo "âœ… ç´¢å¼•åˆ›å»ºæ£€æŸ¥å®Œæˆ"
}

# æ‰§è¡Œæ‰€æœ‰æ£€æŸ¥
check_dangerous_operations
check_migration_naming
check_migration_size
check_index_creation

echo "âœ… è¿ç§»éªŒè¯å®Œæˆ"
```

### 2. å¤‡ä»½åˆ›å»ºè„šæœ¬

```bash
#!/bin/bash
# scripts/create-backup.sh

set -e

BACKUP_ID="$1"
if [ -z "$BACKUP_ID" ]; then
    echo "é”™è¯¯: è¯·æä¾›å¤‡ä»½ID"
    exit 1
fi

echo "=== åˆ›å»ºæ•°æ®åº“å¤‡ä»½: $BACKUP_ID ==="

# é…ç½®
BACKUP_DIR="/var/backups/mysql"
S3_BUCKET="${BACKUP_STORAGE_BUCKET:-easy-erp-backups}"
DATABASE_NAME="${DATABASE_NAME:-easy_erp}"
MYSQL_HOST="${MYSQL_HOST:-localhost}"
MYSQL_USER="${MYSQL_USER:-root}"
MYSQL_PASSWORD="${MYSQL_PASSWORD}"

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p "$BACKUP_DIR"

# ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å
BACKUP_FILE="$BACKUP_DIR/${BACKUP_ID}.sql.gz"
METADATA_FILE="$BACKUP_DIR/${BACKUP_ID}.metadata.json"

echo "åˆ›å»ºå¤‡ä»½æ–‡ä»¶: $BACKUP_FILE"

# åˆ›å»ºæ•°æ®åº“å¤‡ä»½
mysqldump \
    --host="$MYSQL_HOST" \
    --user="$MYSQL_USER" \
    --password="$MYSQL_PASSWORD" \
    --single-transaction \
    --routines \
    --triggers \
    --events \
    --add-drop-table \
    --create-options \
    --disable-keys \
    --extended-insert \
    --quick \
    --lock-tables=false \
    "$DATABASE_NAME" | gzip > "$BACKUP_FILE"

# éªŒè¯å¤‡ä»½æ–‡ä»¶
if [ ! -f "$BACKUP_FILE" ] || [ ! -s "$BACKUP_FILE" ]; then
    echo "âŒ å¤‡ä»½æ–‡ä»¶åˆ›å»ºå¤±è´¥"
    exit 1
fi

# åˆ›å»ºå…ƒæ•°æ®
cat > "$METADATA_FILE" << EOF
{
  "backup_id": "$BACKUP_ID",
  "database_name": "$DATABASE_NAME",
  "created_at": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
  "mysql_version": "$(mysql --version)",
  "file_size": $(stat -f%z "$BACKUP_FILE" 2>/dev/null || stat -c%s "$BACKUP_FILE"),
  "checksum": "$(sha256sum "$BACKUP_FILE" | cut -d' ' -f1)",
  "git_commit": "${GITHUB_SHA:-$(git rev-parse HEAD)}",
  "environment": "${ENVIRONMENT:-production}"
}
EOF

# ä¸Šä¼ åˆ° S3
if command -v aws &> /dev/null; then
    echo "ä¸Šä¼ å¤‡ä»½åˆ° S3..."
    aws s3 cp "$BACKUP_FILE" "s3://$S3_BUCKET/database/$BACKUP_ID.sql.gz"
    aws s3 cp "$METADATA_FILE" "s3://$S3_BUCKET/database/$BACKUP_ID.metadata.json"
    
    # è®¾ç½®ç”Ÿå‘½å‘¨æœŸ
    aws s3api put-object-tagging \
        --bucket "$S3_BUCKET" \
        --key "database/$BACKUP_ID.sql.gz" \
        --tagging 'TagSet=[{Key=Type,Value=DatabaseBackup},{Key=Environment,Value='"$ENVIRONMENT"'}]'
fi

# æ¸…ç†æœ¬åœ°æ—§å¤‡ä»½ï¼ˆä¿ç•™æœ€è¿‘7å¤©ï¼‰
find "$BACKUP_DIR" -name "*.sql.gz" -mtime +7 -delete
find "$BACKUP_DIR" -name "*.metadata.json" -mtime +7 -delete

echo "âœ… å¤‡ä»½åˆ›å»ºå®Œæˆ: $BACKUP_ID"
echo "æ–‡ä»¶å¤§å°: $(du -h "$BACKUP_FILE" | cut -f1)"
echo "æ ¡éªŒå’Œ: $(sha256sum "$BACKUP_FILE" | cut -d' ' -f1)"
```

### 3. ç›‘æ§è„šæœ¬

```bash
#!/bin/bash
# scripts/start-migration-monitoring.sh

set -e

echo "=== å¯åŠ¨è¿ç§»ç›‘æ§ ==="

# é…ç½®
MONITORING_INTERVAL=5
ALERT_WEBHOOK="${ALERT_WEBHOOK_URL}"
DATABASE_URL="${DATABASE_URL}"

# ç›‘æ§å‡½æ•°
monitor_migration() {
    while true; do
        # è·å–å½“å‰æ—¶é—´
        TIMESTAMP=$(date -u +%Y-%m-%dT%H:%M:%SZ)
        
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        if ! mysql --execute="SELECT 1" "$DATABASE_URL" &>/dev/null; then
            send_alert "critical" "æ•°æ®åº“è¿æ¥å¤±è´¥" "æ— æ³•è¿æ¥åˆ°æ•°æ®åº“"
            continue
        fi
        
        # æ£€æŸ¥æ´»è·ƒè¿æ¥æ•°
        CONNECTIONS=$(mysql --execute="SHOW STATUS LIKE 'Threads_connected'" "$DATABASE_URL" | awk 'NR==2 {print $2}')
        if [ "$CONNECTIONS" -gt 100 ]; then
            send_alert "warning" "æ•°æ®åº“è¿æ¥æ•°è¿‡é«˜" "å½“å‰è¿æ¥æ•°: $CONNECTIONS"
        fi
        
        # æ£€æŸ¥é”ç­‰å¾…
        LOCK_WAITS=$(mysql --execute="SELECT COUNT(*) FROM information_schema.INNODB_LOCKS" "$DATABASE_URL" | awk 'NR==2 {print $1}')
        if [ "$LOCK_WAITS" -gt 0 ]; then
            send_alert "warning" "æ£€æµ‹åˆ°é”ç­‰å¾…" "ç­‰å¾…é”æ•°é‡: $LOCK_WAITS"
        fi
        
        # æ£€æŸ¥æ…¢æŸ¥è¯¢
        SLOW_QUERIES=$(mysql --execute="SHOW STATUS LIKE 'Slow_queries'" "$DATABASE_URL" | awk 'NR==2 {print $2}')
        if [ "$SLOW_QUERIES" -gt "${LAST_SLOW_QUERIES:-0}" ]; then
            NEW_SLOW=$(( SLOW_QUERIES - ${LAST_SLOW_QUERIES:-0} ))
            if [ "$NEW_SLOW" -gt 5 ]; then
                send_alert "warning" "æ…¢æŸ¥è¯¢å¢åŠ " "æ–°å¢æ…¢æŸ¥è¯¢: $NEW_SLOW"
            fi
        fi
        LAST_SLOW_QUERIES="$SLOW_QUERIES"
        
        # è®°å½•ç›‘æ§æ•°æ®
        echo "[$TIMESTAMP] è¿æ¥æ•°: $CONNECTIONS, é”ç­‰å¾…: $LOCK_WAITS, æ…¢æŸ¥è¯¢: $SLOW_QUERIES"
        
        sleep "$MONITORING_INTERVAL"
    done
}

# å‘é€å‘Šè­¦
send_alert() {
    local severity="$1"
    local title="$2"
    local message="$3"
    
    if [ -n "$ALERT_WEBHOOK" ]; then
        curl -X POST "$ALERT_WEBHOOK" \
            -H "Content-Type: application/json" \
            -d "{
                \"severity\": \"$severity\",
                \"title\": \"$title\",
                \"message\": \"$message\",
                \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\",
                \"source\": \"migration-monitor\"
            }"
    fi
    
    echo "[ALERT] [$severity] $title: $message"
}

# å¯åŠ¨ç›‘æ§
monitor_migration
```

### 4. å¥åº·æ£€æŸ¥è„šæœ¬

```bash
#!/bin/bash
# scripts/health-check.sh

set -e

echo "=== åº”ç”¨å¥åº·æ£€æŸ¥ ==="

# é…ç½®
APP_URL="${APP_URL:-http://localhost:3000}"
MAX_RETRIES=30
RETRY_INTERVAL=10

# æ£€æŸ¥åº”ç”¨å“åº”
check_app_response() {
    local url="$1"
    local expected_status="${2:-200}"
    
    response=$(curl -s -o /dev/null -w "%{http_code}" "$url" || echo "000")
    
    if [ "$response" = "$expected_status" ]; then
        return 0
    else
        return 1
    fi
}

# æ£€æŸ¥æ•°æ®åº“è¿æ¥
check_database() {
    echo "æ£€æŸ¥æ•°æ®åº“è¿æ¥..."
    
    if check_app_response "$APP_URL/api/health/database"; then
        echo "âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸"
    else
        echo "âŒ æ•°æ®åº“è¿æ¥å¤±è´¥"
        return 1
    fi
}

# æ£€æŸ¥å…³é”®API
check_critical_apis() {
    echo "æ£€æŸ¥å…³é”®API..."
    
    local apis=(
        "/api/health"
        "/api/auth/status"
        "/api/users/profile"
        "/api/orders/list"
    )
    
    for api in "${apis[@]}"; do
        if check_app_response "$APP_URL$api"; then
            echo "âœ… APIæ­£å¸¸: $api"
        else
            echo "âŒ APIå¼‚å¸¸: $api"
            return 1
        fi
    done
}

# æ£€æŸ¥åº”ç”¨æ€§èƒ½
check_performance() {
    echo "æ£€æŸ¥åº”ç”¨æ€§èƒ½..."
    
    # æµ‹è¯•å“åº”æ—¶é—´
    response_time=$(curl -s -o /dev/null -w "%{time_total}" "$APP_URL/api/health")
    
    # è½¬æ¢ä¸ºæ¯«ç§’
    response_time_ms=$(echo "$response_time * 1000" | bc)
    
    if (( $(echo "$response_time_ms < 1000" | bc -l) )); then
        echo "âœ… å“åº”æ—¶é—´æ­£å¸¸: ${response_time_ms}ms"
    else
        echo "âš ï¸  å“åº”æ—¶é—´è¾ƒæ…¢: ${response_time_ms}ms"
    fi
}

# ä¸»æ£€æŸ¥æµç¨‹
main() {
    echo "å¼€å§‹å¥åº·æ£€æŸ¥..."
    
    # ç­‰å¾…åº”ç”¨å¯åŠ¨
    echo "ç­‰å¾…åº”ç”¨å¯åŠ¨..."
    for i in $(seq 1 $MAX_RETRIES); do
        if check_app_response "$APP_URL/api/health"; then
            echo "âœ… åº”ç”¨å·²å¯åŠ¨ (å°è¯• $i/$MAX_RETRIES)"
            break
        else
            if [ $i -eq $MAX_RETRIES ]; then
                echo "âŒ åº”ç”¨å¯åŠ¨è¶…æ—¶"
                exit 1
            fi
            echo "ç­‰å¾…åº”ç”¨å¯åŠ¨... ($i/$MAX_RETRIES)"
            sleep $RETRY_INTERVAL
        fi
    done
    
    # æ‰§è¡Œå„é¡¹æ£€æŸ¥
    check_database
    check_critical_apis
    check_performance
    
    echo "âœ… å¥åº·æ£€æŸ¥å®Œæˆ"
}

main
```

## ğŸ“Š ç›‘æ§é›†æˆ

### 1. GitHub Actions ç›‘æ§æŒ‡æ ‡

```typescript
// src/monitoring/github-actions-metrics.ts
export interface GitHubActionsMetrics {
  // éƒ¨ç½²æŒ‡æ ‡
  deploymentDuration: number
  deploymentSuccess: boolean
  migrationDuration: number
  migrationSuccess: boolean
  
  // è´¨é‡æŒ‡æ ‡
  testCoverage: number
  testPassRate: number
  codeQualityScore: number
  
  // æ€§èƒ½æŒ‡æ ‡
  buildTime: number
  deploymentSize: number
  startupTime: number
  
  // é”™è¯¯æŒ‡æ ‡
  errorCount: number
  warningCount: number
  criticalIssues: number
}

export class GitHubActionsMonitor {
  private influxClient: InfluxDB
  
  constructor() {
    this.influxClient = new InfluxDB({
      url: process.env.INFLUXDB_URL!,
      token: process.env.INFLUXDB_TOKEN!
    })
  }
  
  async recordDeploymentMetrics(metrics: GitHubActionsMetrics) {
    const writeApi = this.influxClient.getWriteApi(
      process.env.INFLUXDB_ORG!,
      process.env.INFLUXDB_BUCKET!
    )
    
    // è®°å½•éƒ¨ç½²æŒ‡æ ‡
    const deploymentPoint = new Point('github_actions_deployment')
      .tag('repository', process.env.GITHUB_REPOSITORY!)
      .tag('branch', process.env.GITHUB_REF_NAME!)
      .tag('commit', process.env.GITHUB_SHA!)
      .floatField('duration', metrics.deploymentDuration)
      .booleanField('success', metrics.deploymentSuccess)
      .floatField('migration_duration', metrics.migrationDuration)
      .booleanField('migration_success', metrics.migrationSuccess)
      .timestamp(new Date())
    
    // è®°å½•è´¨é‡æŒ‡æ ‡
    const qualityPoint = new Point('github_actions_quality')
      .tag('repository', process.env.GITHUB_REPOSITORY!)
      .tag('branch', process.env.GITHUB_REF_NAME!)
      .floatField('test_coverage', metrics.testCoverage)
      .floatField('test_pass_rate', metrics.testPassRate)
      .floatField('code_quality_score', metrics.codeQualityScore)
      .timestamp(new Date())
    
    writeApi.writePoints([deploymentPoint, qualityPoint])
    await writeApi.close()
  }
  
  async createDeploymentAlert(severity: 'info' | 'warning' | 'critical', message: string) {
    const alert = {
      id: `github-actions-${Date.now()}`,
      severity,
      title: 'GitHub Actions éƒ¨ç½²å‘Šè­¦',
      message,
      source: 'github-actions',
      repository: process.env.GITHUB_REPOSITORY,
      commit: process.env.GITHUB_SHA,
      branch: process.env.GITHUB_REF_NAME,
      timestamp: new Date().toISOString()
    }
    
    // å‘é€åˆ°å‘Šè­¦ç³»ç»Ÿ
    await this.sendAlert(alert)
  }
  
  private async sendAlert(alert: any) {
    if (process.env.ALERT_WEBHOOK_URL) {
      await fetch(process.env.ALERT_WEBHOOK_URL, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(alert)
      })
    }
  }
}
```

### 2. éƒ¨ç½²ä»ªè¡¨æ¿é…ç½®

```json
{
  "dashboard": {
    "title": "GitHub Actions éƒ¨ç½²ç›‘æ§",
    "tags": ["github-actions", "deployment", "ci-cd"],
    "time": {
      "from": "now-24h",
      "to": "now"
    },
    "panels": [
      {
        "title": "éƒ¨ç½²æˆåŠŸç‡",
        "type": "stat",
        "targets": [
          {
            "query": "SELECT mean(success) FROM github_actions_deployment WHERE time >= now() - 24h GROUP BY time(1h)"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "min": 0,
            "max": 100,
            "thresholds": {
              "steps": [
                { "color": "red", "value": 0 },
                { "color": "yellow", "value": 95 },
                { "color": "green", "value": 99 }
              ]
            }
          }
        }
      },
      {
        "title": "éƒ¨ç½²æ—¶é•¿è¶‹åŠ¿",
        "type": "timeseries",
        "targets": [
          {
            "query": "SELECT mean(duration) FROM github_actions_deployment WHERE time >= now() - 7d GROUP BY time(1h)"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "s",
            "custom": {
              "drawStyle": "line",
              "lineInterpolation": "smooth"
            }
          }
        }
      },
      {
        "title": "è¿ç§»æ‰§è¡Œç»Ÿè®¡",
        "type": "piechart",
        "targets": [
          {
            "query": "SELECT count(migration_success) FROM github_actions_deployment WHERE time >= now() - 7d GROUP BY migration_success"
          }
        ]
      },
      {
        "title": "æœ€è¿‘éƒ¨ç½²è®°å½•",
        "type": "table",
        "targets": [
          {
            "query": "SELECT time, repository, branch, commit, duration, success FROM github_actions_deployment WHERE time >= now() - 24h ORDER BY time DESC LIMIT 20"
          }
        ]
      }
    ]
  }
}
```

## âœ… éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶
- [ ] æ”¯æŒè‡ªåŠ¨åŒ–æ•°æ®åº“è¿ç§»æµç¨‹
- [ ] å®ç°è¿ç§»å‰è‡ªåŠ¨å¤‡ä»½æœºåˆ¶
- [ ] æ”¯æŒè¿ç§»å¤±è´¥è‡ªåŠ¨å›æ»š
- [ ] é›†æˆç›‘æ§å‘Šè­¦ç³»ç»Ÿ
- [ ] æä¾›å¤šç¯å¢ƒéƒ¨ç½²æ”¯æŒ
- [ ] å®ç°è“ç»¿éƒ¨ç½²ç­–ç•¥

### æ€§èƒ½éªŒæ”¶
- [ ] å®Œæ•´éƒ¨ç½²æµç¨‹ â‰¤ 10åˆ†é’Ÿ
- [ ] è¿ç§»å¤±è´¥å›æ»šæ—¶é—´ â‰¤ 2åˆ†é’Ÿ
- [ ] è‡ªåŠ¨åŒ–éƒ¨ç½²æˆåŠŸç‡ â‰¥ 99%
- [ ] ç›‘æ§å‘Šè­¦å“åº”æ—¶é—´ â‰¤ 30ç§’

### å®‰å…¨éªŒæ”¶
- [ ] è¿ç§»è„šæœ¬å®‰å…¨éªŒè¯
- [ ] æ•æ„Ÿä¿¡æ¯åŠ å¯†å­˜å‚¨
- [ ] æ“ä½œå®¡è®¡æ—¥å¿—å®Œæ•´
- [ ] æƒé™æ§åˆ¶æœºåˆ¶å®Œå–„

### å¯é æ€§éªŒæ”¶
- [ ] æ”¯æŒå¹¶å‘éƒ¨ç½²æ§åˆ¶
- [ ] å¼‚å¸¸æƒ…å†µè‡ªåŠ¨æ¢å¤
- [ ] å®Œæ•´çš„é”™è¯¯å¤„ç†æœºåˆ¶
- [ ] éƒ¨ç½²çŠ¶æ€å®æ—¶è·Ÿè¸ª

### å¯ç»´æŠ¤æ€§éªŒæ”¶
- [ ] æä¾›å®Œæ•´çš„éƒ¨ç½²æ–‡æ¡£
- [ ] æ”¯æŒé…ç½®çƒ­æ›´æ–°
- [ ] æä¾›æ•…éšœæ’æŸ¥æŒ‡å—
- [ ] æ”¯æŒéƒ¨ç½²æµç¨‹è‡ªå®šä¹‰

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¶é—´**: 2025-01-22  
**ä¾èµ–æ–‡æ¡£**: DESIGN_database_sync_optimization.md, BACKUP_RECOVERY_DESIGN.md, MONITORING_ALERT_DESIGN.md  
**çŠ¶æ€**: âœ… GitHub Actionsé›†æˆæ–¹æ¡ˆè®¾è®¡å®Œæˆï¼Œç­‰å¾…å®æ–½ç¡®è®¤